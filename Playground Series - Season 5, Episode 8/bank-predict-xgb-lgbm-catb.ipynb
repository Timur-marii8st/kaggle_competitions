{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"},{"sourceId":9293783,"sourceType":"datasetVersion","datasetId":5626665}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext cudf.pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:51:25.994294Z","iopub.execute_input":"2025-08-05T08:51:25.994868Z","iopub.status.idle":"2025-08-05T08:51:36.513906Z","shell.execute_reply.started":"2025-08-05T08:51:25.994841Z","shell.execute_reply":"2025-08-05T08:51:36.513076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport optuna\nimport gc\nfrom sklearn.model_selection import StratifiedKFold\nfrom pandas.errors import PerformanceWarning\nfrom sklearn.metrics import roc_auc_score\nfrom optuna.samplers import TPESampler\nfrom itertools import combinations\nfrom xgboost import XGBClassifier\nfrom tqdm import tqdm\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n\nwarnings.simplefilter(action=\"ignore\", category=PerformanceWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:51:36.515106Z","iopub.execute_input":"2025-08-05T08:51:36.515612Z","iopub.status.idle":"2025-08-05T08:51:37.515529Z","shell.execute_reply.started":"2025-08-05T08:51:36.515588Z","shell.execute_reply":"2025-08-05T08:51:37.514770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  --- Feature proccesing ----\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv', index_col='id')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e8/test.csv', index_col='id')\norig = pd.read_csv('/kaggle/input/bank-marketing-dataset-full/bank-full.csv', delimiter=';')\norig['y'] = orig['y'].replace({'yes': 1, 'no': 0})\n\nTARGET = 'y'\nNUMS = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\nCATS = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n\ntrain[CATS] = train[CATS].astype('category')\ntest[CATS] = test[CATS].astype('category')\norig[CATS] = orig[CATS].astype('category')\n\nTE_columns = []\n\ncolumns = NUMS + CATS\n\n\n\n# Creating new columns\nfor r in [2]:\n    for cols in tqdm(list(combinations(columns, r))):\n        name = '-'.join(cols)\n    \n        train[name] = train[cols[0]].astype(str)\n        for col in cols[1:]:\n            train[name] = train[name] + '_' + train[col].astype(str)\n    \n        test[name] = test[cols[0]].astype(str)\n        for col in cols[1:]:\n            test[name] = test[name] + '_' + test[col].astype(str)\n    \n        orig[name] = orig[cols[0]].astype(str)\n        for col in cols[1:]:\n            orig[name] = orig[name] + '_' + orig[col].astype(str)\n        \n        combined = pd.concat([train[name], test[name], orig[name]], ignore_index=True)\n        combined, _ = combined.factorize()\n        train[name] = combined[:len(train)]\n        test[name] = combined[len(train):len(train) + len(test)]\n        orig[name] = combined[len(train) + len(test):]\n    \n        TE_columns.append(name)\n\nFEATURES = train.columns.tolist()\nFEATURES.remove(TARGET)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T15:19:36.603678Z","iopub.execute_input":"2025-08-06T15:19:36.604211Z","iopub.status.idle":"2025-08-06T15:19:36.675397Z","shell.execute_reply.started":"2025-08-06T15:19:36.604190Z","shell.execute_reply":"2025-08-06T15:19:36.674352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def target_encode(train, valid, test, col, target=TARGET, kfold=5, smooth=20, agg='mean'):\n    train['kfold'] = ((train.index) % kfold)\n    col_name = '_'.join(col)\n    train[f'TE_{agg.upper()}_' + col_name] = 0.\n    for i in range(kfold):\n        df_tmp = train[train['kfold'] != i]\n        if agg == 'mean': mn = train[target].mean()\n        elif agg == 'median': mn = train[target].median()\n        elif agg == 'min': mn = train[target].min()\n        elif agg == 'max': mn = train[target].max()\n        elif agg == 'nunique': mn = 0\n        df_tmp = df_tmp[col + [target]].groupby(col).agg([agg, 'count']).reset_index()\n        df_tmp.columns = col + [agg, 'count']\n        if agg == 'nunique':\n            df_tmp['TE_tmp'] = df_tmp[agg] / df_tmp['count']\n        else:\n            df_tmp['TE_tmp'] = ((df_tmp[agg] * df_tmp['count']) + (mn * smooth)) / (df_tmp['count'] + smooth)\n        df_tmp_m = train[col + ['kfold', f'TE_{agg.upper()}_' + col_name]].merge(df_tmp, how='left', left_on=col, right_on=col)\n        df_tmp_m.loc[df_tmp_m['kfold'] == i, f'TE_{agg.upper()}_' + col_name] = df_tmp_m.loc[df_tmp_m['kfold'] == i, 'TE_tmp']\n        train[f'TE_{agg.upper()}_' + col_name] = df_tmp_m[f'TE_{agg.upper()}_' + col_name].fillna(mn).values\n\n    df_tmp = train[col + [target]].groupby(col).agg([agg, 'count']).reset_index()\n    if agg == 'mean': mn = train[target].mean()\n    elif agg == 'median': mn = train[target].median()\n    elif agg == 'min': mn = train[target].min()\n    elif agg == 'max': mn = train[target].max()\n    elif agg == 'nunique': mn = 0\n    df_tmp.columns = col + [agg, 'count']\n    if agg == 'nunique':\n        df_tmp['TE_tmp'] = df_tmp[agg] / df_tmp['count']\n    else:\n        df_tmp['TE_tmp'] = ((df_tmp[agg] * df_tmp['count']) + (mn * smooth)) / (df_tmp['count'] + smooth)\n    df_tmp_m = valid[col].merge(df_tmp, how='left', left_on=col, right_on=col)\n    valid[f'TE_{agg.upper()}_' + col_name] = df_tmp_m['TE_tmp'].fillna(mn).values\n    valid[f'TE_{agg.upper()}_' + col_name] = valid[f'TE_{agg.upper()}_' + col_name].astype('float32')\n\n    df_tmp_m = test[col].merge(df_tmp, how='left', left_on=col, right_on=col)\n    test[f'TE_{agg.upper()}_' + col_name] = df_tmp_m['TE_tmp'].fillna(mn).values\n    test[f'TE_{agg.upper()}_' + col_name] = test[f'TE_{agg.upper()}_' + col_name].astype('float32')\n\n    train = train.drop('kfold', axis=1)\n    train[f'TE_{agg.upper()}_' + col_name] = train[f'TE_{agg.upper()}_' + col_name].astype('float32')\n\n    return (train, valid, test)\n\ndef count_encode(train, valid, test, col):\n    counts = train[col].value_counts()\n\n    train[f'CE_{col}'] = train[col].map(counts)\n    valid[f'CE_{col}'] = valid[col].map(counts).fillna(0)\n    test[f'CE_{col}'] = test[col].map(counts).fillna(0)\n    \n    return (train, valid, test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:02:36.731564Z","iopub.execute_input":"2025-08-05T09:02:36.731816Z","iopub.status.idle":"2025-08-05T09:02:36.744500Z","shell.execute_reply.started":"2025-08-05T09:02:36.731790Z","shell.execute_reply":"2025-08-05T09:02:36.743682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oof = np.zeros(len(train))\npred = np.zeros(len(test))\n\noof_xgb = np.zeros(len(train))\npred_xgb = np.zeros(len(test))\n\noof_lgb = np.zeros(len(train))\npred_lgb = np.zeros(len(test))\n\noof_cat = np.zeros(len(train))\npred_cat = np.zeros(len(test))\n\nskf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\nfor idx, (train_idx, val_idx) in enumerate(skf.split(train, train[TARGET])):\n    print(f\"========== FOLD {idx+1} ==========\")\n    X_train, X_val = train.loc[train_idx, FEATURES], train.loc[val_idx, FEATURES]\n    y_train, y_val = train.loc[train_idx, TARGET], train.loc[val_idx, TARGET]\n    X_test = test.copy()\n\n    # Аугментация и Feature Engineering (этот блок остается без изменений)\n    X_train = pd.concat([X_train, orig[FEATURES]])\n    y_train = pd.concat([y_train, orig[TARGET]])\n\n    for col in tqdm(TE_columns):\n        X_train, X_val, X_test = target_encode(pd.concat([X_train, y_train], axis=1), X_val, X_test, [col], smooth=10, agg='mean')\n        X_train = X_train.drop(TARGET, axis=1)\n        X_train, X_val, X_test = count_encode(X_train, X_val, X_test, col)\n    \n        X_train = X_train.drop(col, axis=1)\n        X_val = X_val.drop(col, axis=1)\n        X_test = X_test.drop(col, axis=1)\n        \n    # XGBoost, CatBoost и LightGBM могут работать с типом 'category' напрямую\n    # Убедимся, что типы данных правильные после всех манипуляций\n    X_train[CATS] = X_train[CATS].astype('category')\n    X_val[CATS] = X_val[CATS].astype('category')\n    X_test[CATS] = X_test[CATS].astype('category')\n\n    # --- 1. Обучение XGBoost ---\n    print(\"\\n--- Training XGBoost ---\")\n    param_grid_xgb = {'colsample_bytree': 0.34, 'subsample': 0.89, 'reg_lambda': 4.06, 'reg_alpha': 2.91, 'max_depth': 8}\n    model_xgb = XGBClassifier(**param_grid_xgb, \n                              n_estimators=10000,\n                              objective='binary:logistic', eval_metric='auc', learning_rate=0.01,\n                              early_stopping_rounds=200, random_state=42+idx,\n                              enable_categorical=True, device='cuda', n_jobs=-1)\n    \n    model_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n    \n    oof_xgb[val_idx] = model_xgb.predict_proba(X_val)[:, 1]\n    pred_xgb += model_xgb.predict_proba(X_test)[:, 1]\n    print(f'XGB Fold {idx + 1} AUC: {roc_auc_score(y_val, oof_xgb[val_idx])}')\n    \n    # --- 2. Обучение LightGBM ---\n    print(\"\\n--- Training LightGBM ---\")\n    params_lgb = {'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.01, 'n_estimators': 10000,\n                  'lambda_l1': 0.1, 'lambda_l2': 0.1, 'num_leaves': 31, 'feature_fraction': 0.7,\n                  'bagging_fraction': 0.7, 'bagging_freq': 1, 'verbose': -1, 'n_jobs': -1, 'seed': 42+idx}\n                  \n    model_lgb = lgb.LGBMClassifier(**params_lgb)\n    \n    model_lgb.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n                  callbacks=[lgb.early_stopping(200, verbose=False)])\n\n    oof_lgb[val_idx] = model_lgb.predict_proba(X_val)[:, 1]\n    pred_lgb += model_lgb.predict_proba(X_test)[:, 1]\n    print(f'LGB Fold {idx + 1} AUC: {roc_auc_score(y_val, oof_lgb[val_idx])}')\n    \n    # --- 3. Обучение CatBoost ---\n    print(\"\\n--- Training CatBoost ---\")\n    # CatBoost лучше всего передать список категориальных признаков\n    categorical_features_indices = [X_train.columns.get_loc(col) for col in CATS]\n    \n    model_cat = CatBoostClassifier(iterations=10000, learning_rate=0.02, loss_function='Logloss', eval_metric='AUC',\n                                   random_seed=42+idx, verbose=0, cat_features=CATS,\n                                   early_stopping_rounds=200, task_type=\"GPU\") # Используем GPU\n\n    model_cat.fit(X_train, y_train, eval_set=(X_val, y_val))\n    \n    oof_cat[val_idx] = model_cat.predict_proba(X_val)[:, 1]\n    pred_cat += model_cat.predict_proba(X_test)[:, 1]\n    print(f'CAT Fold {idx + 1} AUC: {roc_auc_score(y_val, oof_cat[val_idx])}')\n\n    print(f\"CV AUC XGB: {roc_auc_score(train[TARGET], oof_xgb)}\")\n    print(f\"CV AUC LGB: {roc_auc_score(train[TARGET], oof_lgb)}\")\n    print(f\"CV AUC CAT: {roc_auc_score(train[TARGET], oof_cat)}\")\n\n    # делим накопленные предсказания на количество фолдов\n    pred_xgb /= skf.n_splits\n    pred_lgb /= skf.n_splits\n    pred_cat /= skf.n_splits\n    \n    # Простое усреднение\n    ensemble_pred = (pred_xgb + pred_lgb + pred_cat) / 3\n    \n    # Также можно проверить качество ансамбля на OOF-предсказаниях\n    ensemble_oof = (oof_xgb + oof_lgb + oof_cat) / 3\n    print(f\"\\nCV AUC Ensemble: {roc_auc_score(train[TARGET], ensemble_oof)}\")\n\n    # Освобождаем память\n    del model_xgb, model_lgb, model_cat, X_train, X_val, y_train, y_val, X_test\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:02:36.745826Z","iopub.execute_input":"2025-08-05T09:02:36.746078Z","iopub.status.idle":"2025-08-05T09:38:13.640589Z","shell.execute_reply.started":"2025-08-05T09:02:36.746054Z","shell.execute_reply":"2025-08-05T09:38:13.639791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/playground-series-s5e8/sample_submission.csv')\nsubmission['y'] = ensemble_pred\nsubmission.to_csv('xgb.csv', index=False)\npd.DataFrame({'xgb_oof': oof}).to_csv('xgb_oof.csv', index=False)\npd.DataFrame({'xgb_pred': pred}).to_csv('xgb_pred.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:38:13.641470Z","iopub.execute_input":"2025-08-05T09:38:13.641739Z","iopub.status.idle":"2025-08-05T09:38:13.778108Z","shell.execute_reply.started":"2025-08-05T09:38:13.641715Z","shell.execute_reply":"2025-08-05T09:38:13.777232Z"}},"outputs":[],"execution_count":null}]}