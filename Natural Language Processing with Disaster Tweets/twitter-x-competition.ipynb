{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1fe47d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:27:50.973039Z",
     "iopub.status.busy": "2025-05-30T17:27:50.972739Z",
     "iopub.status.idle": "2025-05-30T17:28:05.856574Z",
     "shell.execute_reply": "2025-05-30T17:28:05.855981Z"
    },
    "papermill": {
     "duration": 14.889163,
     "end_time": "2025-05-30T17:28:05.858168",
     "exception": false,
     "start_time": "2025-05-30T17:27:50.969005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import torch._dynamo\n",
    "\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae97adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:28:05.863978Z",
     "iopub.status.busy": "2025-05-30T17:28:05.863588Z",
     "iopub.status.idle": "2025-05-30T17:28:05.919401Z",
     "shell.execute_reply": "2025-05-30T17:28:05.918883Z"
    },
    "papermill": {
     "duration": 0.059764,
     "end_time": "2025-05-30T17:28:05.920563",
     "exception": false,
     "start_time": "2025-05-30T17:28:05.860799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edaa2e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:28:05.925760Z",
     "iopub.status.busy": "2025-05-30T17:28:05.925546Z",
     "iopub.status.idle": "2025-05-30T17:28:05.934503Z",
     "shell.execute_reply": "2025-05-30T17:28:05.934000Z"
    },
    "papermill": {
     "duration": 0.012753,
     "end_time": "2025-05-30T17:28:05.935578",
     "exception": false,
     "start_time": "2025-05-30T17:28:05.922825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Конфигурац ---\n",
    "class CFG:\n",
    "    MODEL_NAME = 'answerdotai/ModernBERT-base'\n",
    "    MAX_LENGTH = 104\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 4  \n",
    "    LEARNING_RATE = 2e-5\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    WARMUP_RATIO = 0.1\n",
    "    NUM_CLASSES = 2\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    SEED = 42\n",
    "    OUTPUT_DIR = '/kaggle/working/'\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa8a3ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:28:05.940697Z",
     "iopub.status.busy": "2025-05-30T17:28:05.940499Z",
     "iopub.status.idle": "2025-05-30T17:28:05.956379Z",
     "shell.execute_reply": "2025-05-30T17:28:05.955869Z"
    },
    "papermill": {
     "duration": 0.019602,
     "end_time": "2025-05-30T17:28:05.957376",
     "exception": false,
     "start_time": "2025-05-30T17:28:05.937774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.drop(['location'], axis=1, inplace=True)\n",
    "test_df.drop(['location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64631f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:28:05.962311Z",
     "iopub.status.busy": "2025-05-30T17:28:05.962106Z",
     "iopub.status.idle": "2025-05-30T17:28:05.970112Z",
     "shell.execute_reply": "2025-05-30T17:28:05.969587Z"
    },
    "papermill": {
     "duration": 0.011636,
     "end_time": "2025-05-30T17:28:05.971117",
     "exception": false,
     "start_time": "2025-05-30T17:28:05.959481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.fillna({'keyword': train_df['keyword'].mode()[0]}, inplace=True)\n",
    "test_df.fillna({'keyword': train_df['keyword'].mode()[0]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03395435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:28:05.975931Z",
     "iopub.status.busy": "2025-05-30T17:28:05.975713Z",
     "iopub.status.idle": "2025-05-30T17:28:05.981348Z",
     "shell.execute_reply": "2025-05-30T17:28:05.980875Z"
    },
    "papermill": {
     "duration": 0.0091,
     "end_time": "2025-05-30T17:28:05.982298",
     "exception": false,
     "start_time": "2025-05-30T17:28:05.973198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Создание Dataset ---\n",
    "class DisasterTweetDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length, is_test=False):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.is_test = is_test\n",
    "        self.texts = df['text'].values\n",
    "        self.keywords = df['keyword'].values\n",
    "        if not self.is_test:\n",
    "            self.labels = df['target'].values\n",
    "        self.ids = df['id'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        keyword = str(self.keywords[idx])\n",
    "\n",
    "        # Формируем входной текст: \"keyword [SEP] text [SEP]\"\n",
    "        text = f\"{keyword}{self.tokenizer.sep_token}{text}\"\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True, # Добавляет [CLS] и [SEP]\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0)\n",
    "        }\n",
    "        \n",
    "        current_id = self.ids[idx] # Сохраняем ID\n",
    "\n",
    "        if not self.is_test:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return item\n",
    "        else:\n",
    "            # Для тестового набора данных возвращаем и ID\n",
    "            return item, current_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097c724b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:28:05.987152Z",
     "iopub.status.busy": "2025-05-30T17:28:05.986950Z",
     "iopub.status.idle": "2025-05-30T17:28:07.299794Z",
     "shell.execute_reply": "2025-05-30T17:28:07.299240Z"
    },
    "papermill": {
     "duration": 1.316698,
     "end_time": "2025-05-30T17:28:07.301116",
     "exception": false,
     "start_time": "2025-05-30T17:28:05.984418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a27611fe6ea4afe83a594acd1f9fc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f39f4fc0744cec8a6f0651e222b9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.13M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684e70fab7ca4172b1598601368da43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.MODEL_NAME) \n",
    "\n",
    "# --- Разделение на обучающую и валидационную выборки ---\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df[['id','keyword', 'text']],\n",
    "    train_df['target'],\n",
    "    test_size=0.2,\n",
    "    random_state=CFG.SEED,\n",
    "    stratify=train_df['target']\n",
    ")\n",
    "\n",
    "train_split_df = pd.DataFrame({\n",
    "    'id': train_texts['id'],\n",
    "    'keyword': train_texts['keyword'],\n",
    "    'text': train_texts['text'],\n",
    "    'target': train_labels\n",
    "})\n",
    "\n",
    "val_split_df = pd.DataFrame({\n",
    "    'id': val_texts['id'],\n",
    "    'keyword': val_texts['keyword'],\n",
    "    'text': val_texts['text'],\n",
    "    'target': val_labels\n",
    "})\n",
    "\n",
    "\n",
    "train_dataset = DisasterTweetDataset(train_split_df, tokenizer, CFG.MAX_LENGTH)\n",
    "val_dataset = DisasterTweetDataset(val_split_df, tokenizer, CFG.MAX_LENGTH)\n",
    "test_dataset = DisasterTweetDataset(test_df, tokenizer, CFG.MAX_LENGTH, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a1b5e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:28:07.307152Z",
     "iopub.status.busy": "2025-05-30T17:28:07.306916Z",
     "iopub.status.idle": "2025-05-30T17:28:25.120352Z",
     "shell.execute_reply": "2025-05-30T17:28:25.119650Z"
    },
    "papermill": {
     "duration": 17.817893,
     "end_time": "2025-05-30T17:28:25.121768",
     "exception": false,
     "start_time": "2025-05-30T17:28:07.303875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5b5879cdac4271b9a2a383d586a0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 17:28:09.797333: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748626089.985558      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748626090.045370      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bbd3d385cf4d5286fd5622a8d17fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# --- Модель ---\n",
    "model_config = AutoConfig.from_pretrained(\n",
    "    CFG.MODEL_NAME, \n",
    "    num_labels=CFG.NUM_CLASSES\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        CFG.MODEL_NAME,\n",
    "        config=model_config\n",
    "    )\n",
    "\n",
    "model.to(CFG.DEVICE)\n",
    "\n",
    "# --- Оптимизатор и скедулер ---\n",
    "optimizer = AdamW(\n",
    "    params=model.parameters(),      \n",
    "    lr=CFG.LEARNING_RATE,                      \n",
    "    betas=(0.9, 0.999),          \n",
    "    eps=1e-8,                      \n",
    "    weight_decay=CFG.WEIGHT_DECAY,\n",
    "    amsgrad=False                 \n",
    ")\n",
    "num_training_steps = len(train_loader) * CFG.EPOCHS\n",
    "num_warmup_steps = int(CFG.WARMUP_RATIO * num_training_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0fc5d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:28:25.129323Z",
     "iopub.status.busy": "2025-05-30T17:28:25.128873Z",
     "iopub.status.idle": "2025-05-30T17:28:25.138687Z",
     "shell.execute_reply": "2025-05-30T17:28:25.138092Z"
    },
    "papermill": {
     "duration": 0.01468,
     "end_time": "2025-05-30T17:28:25.139916",
     "exception": false,
     "start_time": "2025-05-30T17:28:25.125236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Функции обучения и оценки ---\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"  Batch {batch_idx}/{len(data_loader)}, Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate_epoch(model, data_loader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds_probs.extend(probs)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    competition_log_loss = log_loss(all_labels, all_preds_probs, labels=[0, 1])\n",
    "\n",
    "    return avg_loss, competition_log_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1669bbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:28:25.148366Z",
     "iopub.status.busy": "2025-05-30T17:28:25.148152Z",
     "iopub.status.idle": "2025-05-30T17:35:07.811798Z",
     "shell.execute_reply": "2025-05-30T17:35:07.811026Z"
    },
    "papermill": {
     "duration": 402.66939,
     "end_time": "2025-05-30T17:35:07.812940",
     "exception": false,
     "start_time": "2025-05-30T17:28:25.143550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT compiled_embeddings /usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py line 212 \n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0530 17:28:29.582000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.004000 19 torch/_inductor/utils.py:1137] [1/0] Not enough SMs to use max_autotune_gemm mode\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT compiled_mlp /usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py line 531 \n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0530 17:28:31.066000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py line 245 \n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0530 17:28:31.542000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /usr/local/lib/python3.11/dist-packages/transformers/activations.py line 77 \n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] \n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0530 17:28:31.780000 19 torch/_dynamo/convert_frame.py:1233] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0/381, Train Loss: 0.8148\n",
      "  Batch 100/381, Train Loss: 0.2705\n",
      "  Batch 200/381, Train Loss: 0.4946\n",
      "  Batch 300/381, Train Loss: 0.1455\n",
      "Epoch 1 Summary: \n",
      "  Train Loss: 0.4840\n",
      "  Val Loss: 0.3932\n",
      "  Val LogLoss (Competition Metric): 0.3926\n",
      "  New best model saved to /kaggle/working/answerdotai_ModernBERT-base_best.bin with LogLoss: 0.3926\n",
      "--- Epoch 2/4 ---\n",
      "  Batch 0/381, Train Loss: 0.4805\n",
      "  Batch 100/381, Train Loss: 0.0980\n",
      "  Batch 200/381, Train Loss: 0.3808\n",
      "  Batch 300/381, Train Loss: 0.5372\n",
      "Epoch 2 Summary: \n",
      "  Train Loss: 0.3325\n",
      "  Val Loss: 0.4085\n",
      "  Val LogLoss (Competition Metric): 0.4075\n",
      "--- Epoch 3/4 ---\n",
      "  Batch 0/381, Train Loss: 0.3469\n",
      "  Batch 100/381, Train Loss: 0.2219\n",
      "  Batch 200/381, Train Loss: 0.2173\n",
      "  Batch 300/381, Train Loss: 0.2209\n",
      "Epoch 3 Summary: \n",
      "  Train Loss: 0.2196\n",
      "  Val Loss: 0.4245\n",
      "  Val LogLoss (Competition Metric): 0.4225\n",
      "--- Epoch 4/4 ---\n",
      "  Batch 0/381, Train Loss: 0.0842\n",
      "  Batch 100/381, Train Loss: 0.1980\n",
      "  Batch 200/381, Train Loss: 0.0964\n",
      "  Batch 300/381, Train Loss: 0.1310\n",
      "Epoch 4 Summary: \n",
      "  Train Loss: 0.1233\n",
      "  Val Loss: 0.5687\n",
      "  Val LogLoss (Competition Metric): 0.5665\n",
      "--- Training Finished ---\n",
      "Best Validation LogLoss: 0.3926\n"
     ]
    }
   ],
   "source": [
    "# --- Цикл трейнинга, рокки 10 бля ---\n",
    "best_val_log_loss = float('inf')\n",
    "best_model_path = os.path.join(CFG.OUTPUT_DIR, f\"{CFG.MODEL_NAME.replace('/', '_')}_best.bin\")\n",
    "\n",
    "for epoch in range(CFG.EPOCHS):\n",
    "    print(f\"--- Epoch {epoch+1}/{CFG.EPOCHS} ---\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, CFG.DEVICE, criterion)\n",
    "    val_loss, val_log_loss = evaluate_epoch(model, val_loader, CFG.DEVICE, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Summary: \")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  Val LogLoss (Competition Metric): {val_log_loss:.4f}\")\n",
    "\n",
    "    if val_log_loss < best_val_log_loss:\n",
    "        best_val_log_loss = val_log_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"  New best model saved to {best_model_path} with LogLoss: {val_log_loss:.4f}\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"--- Training Finished ---\")\n",
    "print(f\"Best Validation LogLoss: {best_val_log_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31af1de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:35:07.825923Z",
     "iopub.status.busy": "2025-05-30T17:35:07.825400Z",
     "iopub.status.idle": "2025-05-30T17:35:23.360265Z",
     "shell.execute_reply": "2025-05-30T17:35:23.359425Z"
    },
    "papermill": {
     "duration": 15.542601,
     "end_time": "2025-05-30T17:35:23.361635",
     "exception": false,
     "start_time": "2025-05-30T17:35:07.819034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Предсказание на тестовых данных ---\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "test_preds_classes = []\n",
    "test_ids_ordered = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_ids in test_loader:\n",
    "        input_ids = batch_data['input_ids'].to(CFG.DEVICE)\n",
    "        attention_mask = batch_data['attention_mask'].to(CFG.DEVICE)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        predicted_classes_batch = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "        test_preds_classes.extend(predicted_classes_batch)\n",
    "        \n",
    "        test_ids_ordered.extend(batch_ids.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17570c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:35:23.374690Z",
     "iopub.status.busy": "2025-05-30T17:35:23.374432Z",
     "iopub.status.idle": "2025-05-30T17:35:23.399593Z",
     "shell.execute_reply": "2025-05-30T17:35:23.398973Z"
    },
    "papermill": {
     "duration": 0.032772,
     "end_time": "2025-05-30T17:35:23.400751",
     "exception": false,
     "start_time": "2025-05-30T17:35:23.367979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created at: /kaggle/working/submission.csv\n",
      "Top 5 rows of submission:\n",
      "   id  target\n",
      "0   0       1\n",
      "1   2       1\n",
      "2   3       1\n",
      "3   9       1\n",
      "4  11       1\n"
     ]
    }
   ],
   "source": [
    "# --- Формирование файла сабмита ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids_ordered,\n",
    "    'target': test_preds_classes \n",
    "})\n",
    "\n",
    "submission_path = os.path.join(CFG.OUTPUT_DIR, 'submission.csv')\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission file created at: {submission_path}\")\n",
    "print(\"Top 5 rows of submission:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 459.227855,
   "end_time": "2025-05-30T17:35:26.124912",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-30T17:27:46.897057",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "107196e90fcc4843b0bb1282b0075658": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "115c6ca890374805b487dacdd1a902ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "117dde85f8634e2685c4d79268582362": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b5038460e7ee4eec8c41f1d96620c785",
       "placeholder": "​",
       "style": "IPY_MODEL_817bab8d2d3547b6b51e8b16ee905582",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "1d5b5879cdac4271b9a2a383d586a0a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3b5bbf9c916e4e63989eec67b907cfe8",
        "IPY_MODEL_f0e44b470bfd4f5ba321ceebdb52a270",
        "IPY_MODEL_99970278caed4a7088ffd638760821a8"
       ],
       "layout": "IPY_MODEL_e065bef19f0f41078268f3b1f50e0ee0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1fad7e875bc14fb9942cae9fa2e621f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21bbd3d385cf4d5286fd5622a8d17fc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c1d27658b876465d9e4503c42ed839b6",
        "IPY_MODEL_8789db4baf95484cadc4b76ad9a95145",
        "IPY_MODEL_9612b6e268c84dc0b8ed92c7f77dcbe8"
       ],
       "layout": "IPY_MODEL_3f20e82d749f4f069a1a730889edcc74",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2782f22ff7a54dc6b35dbecaadb8b6a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28df155de684460bbd4f58c59629f26f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2a23f68cfd6a447989d8e655a48717b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2fbb297df2684388ba29f22dd8419bc0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30421c2ccd5f4662906ad0a436b35498": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33bb60d5638c4b61a3682df5f8e733ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3a27611fe6ea4afe83a594acd1f9fc83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_117dde85f8634e2685c4d79268582362",
        "IPY_MODEL_43c5cc9f571143608d3ab1e78209f7f5",
        "IPY_MODEL_8584abef94054e3fb948734b96e7fcb0"
       ],
       "layout": "IPY_MODEL_66c84a4958a445779768908883cc5c7c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3b5bbf9c916e4e63989eec67b907cfe8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e387a63984da4bd6ac1d6e6205cb68bb",
       "placeholder": "​",
       "style": "IPY_MODEL_5e3530e5ccfb4ad4ab32a88d73ffeba3",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "3f20e82d749f4f069a1a730889edcc74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4159a9e7807649f98af35ce19542701d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43c5cc9f571143608d3ab1e78209f7f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2fbb297df2684388ba29f22dd8419bc0",
       "max": 20810.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a7aac4c50b9c447cb148bc8aeaa929e8",
       "tabbable": null,
       "tooltip": null,
       "value": 20810.0
      }
     },
     "5638db7fdc5c4055969d84f10bf89892": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5b3e02109cf3441dade2a366ede0dd7b",
       "placeholder": "​",
       "style": "IPY_MODEL_115c6ca890374805b487dacdd1a902ad",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "56b4ffd934f64d54bcf6b1514a7e7658": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "57d7a97891aa402db00449f284d7a8b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5b3e02109cf3441dade2a366ede0dd7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e3530e5ccfb4ad4ab32a88d73ffeba3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6591d1f9cc224a82a66ffc08ca6090b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "66c84a4958a445779768908883cc5c7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "684e70fab7ca4172b1598601368da43a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ced6e5827d0b480cb332e9b9e551b3ae",
        "IPY_MODEL_cbebfbbb28b54ef1b5ab239e8ca8dca4",
        "IPY_MODEL_75843a3901774e52b1bede16e2735e06"
       ],
       "layout": "IPY_MODEL_8bb3922659ad43e19b86567eeb3ffd9d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6cf68b1dcac14728a6051b93d3383b92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "75843a3901774e52b1bede16e2735e06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4159a9e7807649f98af35ce19542701d",
       "placeholder": "​",
       "style": "IPY_MODEL_8667364337f940609942b6e5ac3b5088",
       "tabbable": null,
       "tooltip": null,
       "value": " 694/694 [00:00&lt;00:00, 96.1kB/s]"
      }
     },
     "78f39f4fc0744cec8a6f0651e222b9f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5638db7fdc5c4055969d84f10bf89892",
        "IPY_MODEL_9f60e2a55e3c4945ab4bf9b6cc5780cb",
        "IPY_MODEL_dcc987564fad4fb1a28c666a561d88b2"
       ],
       "layout": "IPY_MODEL_d8cc4e93928c4720b0f92690de8284a4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "817bab8d2d3547b6b51e8b16ee905582": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8584abef94054e3fb948734b96e7fcb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1fad7e875bc14fb9942cae9fa2e621f6",
       "placeholder": "​",
       "style": "IPY_MODEL_33bb60d5638c4b61a3682df5f8e733ab",
       "tabbable": null,
       "tooltip": null,
       "value": " 20.8k/20.8k [00:00&lt;00:00, 2.21MB/s]"
      }
     },
     "8667364337f940609942b6e5ac3b5088": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8789db4baf95484cadc4b76ad9a95145": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9372b469e6f64da5825870007a5d651b",
       "max": 598635032.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_57d7a97891aa402db00449f284d7a8b2",
       "tabbable": null,
       "tooltip": null,
       "value": 598635032.0
      }
     },
     "8bb3922659ad43e19b86567eeb3ffd9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bbed7c5331949a89de124809a02bade": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8bcc6fc1be694328b637093f12f7c0dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d6f8e67324c49b685d5addde504a799": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "906ca73d3e0f487fb6448d373f1f4329": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9206effc63524cdf9b2aa97c857b2d5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9372b469e6f64da5825870007a5d651b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9612b6e268c84dc0b8ed92c7f77dcbe8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e0c7947f9c3b48658906c2b7c58595bc",
       "placeholder": "​",
       "style": "IPY_MODEL_28df155de684460bbd4f58c59629f26f",
       "tabbable": null,
       "tooltip": null,
       "value": " 599M/599M [00:02&lt;00:00, 313MB/s]"
      }
     },
     "99970278caed4a7088ffd638760821a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8bcc6fc1be694328b637093f12f7c0dd",
       "placeholder": "​",
       "style": "IPY_MODEL_8bbed7c5331949a89de124809a02bade",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.19k/1.19k [00:00&lt;00:00, 144kB/s]"
      }
     },
     "9f60e2a55e3c4945ab4bf9b6cc5780cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2782f22ff7a54dc6b35dbecaadb8b6a5",
       "max": 2132967.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2a23f68cfd6a447989d8e655a48717b4",
       "tabbable": null,
       "tooltip": null,
       "value": 2132967.0
      }
     },
     "a7aac4c50b9c447cb148bc8aeaa929e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab7159f78fb4444cb35659367fc5531c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b5038460e7ee4eec8c41f1d96620c785": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c1d27658b876465d9e4503c42ed839b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8d6f8e67324c49b685d5addde504a799",
       "placeholder": "​",
       "style": "IPY_MODEL_107196e90fcc4843b0bb1282b0075658",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "cbebfbbb28b54ef1b5ab239e8ca8dca4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6cf68b1dcac14728a6051b93d3383b92",
       "max": 694.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ab7159f78fb4444cb35659367fc5531c",
       "tabbable": null,
       "tooltip": null,
       "value": 694.0
      }
     },
     "ced6e5827d0b480cb332e9b9e551b3ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f22742896015438aaec656a3cd00aa03",
       "placeholder": "​",
       "style": "IPY_MODEL_9206effc63524cdf9b2aa97c857b2d5d",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "d8cc4e93928c4720b0f92690de8284a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcc987564fad4fb1a28c666a561d88b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_30421c2ccd5f4662906ad0a436b35498",
       "placeholder": "​",
       "style": "IPY_MODEL_6591d1f9cc224a82a66ffc08ca6090b1",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.13M/2.13M [00:00&lt;00:00, 11.6MB/s]"
      }
     },
     "e065bef19f0f41078268f3b1f50e0ee0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0c7947f9c3b48658906c2b7c58595bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e387a63984da4bd6ac1d6e6205cb68bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0e44b470bfd4f5ba321ceebdb52a270": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_56b4ffd934f64d54bcf6b1514a7e7658",
       "max": 1193.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_906ca73d3e0f487fb6448d373f1f4329",
       "tabbable": null,
       "tooltip": null,
       "value": 1193.0
      }
     },
     "f22742896015438aaec656a3cd00aa03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
